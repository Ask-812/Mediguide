{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7640586797066015,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015281173594132029,
      "grad_norm": 0.36445149779319763,
      "learning_rate": 0.00019700488997555012,
      "loss": 2.8876,
      "step": 50
    },
    {
      "epoch": 0.030562347188264057,
      "grad_norm": 0.5996271371841431,
      "learning_rate": 0.0001939486552567237,
      "loss": 2.7063,
      "step": 100
    },
    {
      "epoch": 0.04584352078239609,
      "grad_norm": 0.7483192682266235,
      "learning_rate": 0.0001908924205378973,
      "loss": 2.4613,
      "step": 150
    },
    {
      "epoch": 0.061124694376528114,
      "grad_norm": 0.5746106505393982,
      "learning_rate": 0.00018783618581907091,
      "loss": 2.4324,
      "step": 200
    },
    {
      "epoch": 0.07640586797066015,
      "grad_norm": 0.7491904497146606,
      "learning_rate": 0.0001847799511002445,
      "loss": 2.3654,
      "step": 250
    },
    {
      "epoch": 0.09168704156479218,
      "grad_norm": 0.7792553305625916,
      "learning_rate": 0.0001817237163814181,
      "loss": 2.3295,
      "step": 300
    },
    {
      "epoch": 0.1069682151589242,
      "grad_norm": 0.8659417629241943,
      "learning_rate": 0.00017866748166259168,
      "loss": 2.2191,
      "step": 350
    },
    {
      "epoch": 0.12224938875305623,
      "grad_norm": 1.2277331352233887,
      "learning_rate": 0.0001756112469437653,
      "loss": 2.2549,
      "step": 400
    },
    {
      "epoch": 0.13753056234718827,
      "grad_norm": 0.9412168860435486,
      "learning_rate": 0.00017255501222493888,
      "loss": 2.1944,
      "step": 450
    },
    {
      "epoch": 0.1528117359413203,
      "grad_norm": 0.9356924295425415,
      "learning_rate": 0.00016949877750611247,
      "loss": 2.1947,
      "step": 500
    },
    {
      "epoch": 0.16809290953545233,
      "grad_norm": 0.7516841888427734,
      "learning_rate": 0.00016644254278728608,
      "loss": 2.1403,
      "step": 550
    },
    {
      "epoch": 0.18337408312958436,
      "grad_norm": 1.0194225311279297,
      "learning_rate": 0.00016338630806845967,
      "loss": 2.2022,
      "step": 600
    },
    {
      "epoch": 0.1986552567237164,
      "grad_norm": 1.3157240152359009,
      "learning_rate": 0.00016033007334963326,
      "loss": 2.1708,
      "step": 650
    },
    {
      "epoch": 0.2139364303178484,
      "grad_norm": 0.9354068636894226,
      "learning_rate": 0.00015727383863080684,
      "loss": 2.0457,
      "step": 700
    },
    {
      "epoch": 0.22921760391198043,
      "grad_norm": 0.7232644557952881,
      "learning_rate": 0.00015421760391198046,
      "loss": 2.1357,
      "step": 750
    },
    {
      "epoch": 0.24449877750611246,
      "grad_norm": 0.9209660887718201,
      "learning_rate": 0.00015116136919315405,
      "loss": 2.1331,
      "step": 800
    },
    {
      "epoch": 0.2597799511002445,
      "grad_norm": 1.5986502170562744,
      "learning_rate": 0.00014810513447432763,
      "loss": 2.0193,
      "step": 850
    },
    {
      "epoch": 0.27506112469437655,
      "grad_norm": 1.409956455230713,
      "learning_rate": 0.00014504889975550122,
      "loss": 2.1434,
      "step": 900
    },
    {
      "epoch": 0.29034229828850855,
      "grad_norm": 1.4498015642166138,
      "learning_rate": 0.00014199266503667484,
      "loss": 2.0332,
      "step": 950
    },
    {
      "epoch": 0.3056234718826406,
      "grad_norm": 0.8704297542572021,
      "learning_rate": 0.00013893643031784842,
      "loss": 2.0545,
      "step": 1000
    },
    {
      "epoch": 0.3209046454767726,
      "grad_norm": 1.0245006084442139,
      "learning_rate": 0.000135880195599022,
      "loss": 2.0694,
      "step": 1050
    },
    {
      "epoch": 0.33618581907090467,
      "grad_norm": 0.922419548034668,
      "learning_rate": 0.0001328239608801956,
      "loss": 2.0648,
      "step": 1100
    },
    {
      "epoch": 0.35146699266503667,
      "grad_norm": 0.7149419784545898,
      "learning_rate": 0.00012976772616136921,
      "loss": 2.111,
      "step": 1150
    },
    {
      "epoch": 0.36674816625916873,
      "grad_norm": 1.1307309865951538,
      "learning_rate": 0.0001267114914425428,
      "loss": 2.0522,
      "step": 1200
    },
    {
      "epoch": 0.38202933985330073,
      "grad_norm": 1.1224207878112793,
      "learning_rate": 0.0001236552567237164,
      "loss": 1.9806,
      "step": 1250
    },
    {
      "epoch": 0.3973105134474328,
      "grad_norm": 0.8507397174835205,
      "learning_rate": 0.00012059902200488998,
      "loss": 2.1021,
      "step": 1300
    },
    {
      "epoch": 0.4125916870415648,
      "grad_norm": 0.8560908436775208,
      "learning_rate": 0.00011754278728606358,
      "loss": 2.0072,
      "step": 1350
    },
    {
      "epoch": 0.4278728606356968,
      "grad_norm": 0.7703226208686829,
      "learning_rate": 0.00011448655256723717,
      "loss": 2.0227,
      "step": 1400
    },
    {
      "epoch": 0.44315403422982885,
      "grad_norm": 0.7520902156829834,
      "learning_rate": 0.00011143031784841075,
      "loss": 2.0591,
      "step": 1450
    },
    {
      "epoch": 0.45843520782396086,
      "grad_norm": 1.1568080186843872,
      "learning_rate": 0.00010837408312958434,
      "loss": 2.0548,
      "step": 1500
    },
    {
      "epoch": 0.4737163814180929,
      "grad_norm": 0.8725346326828003,
      "learning_rate": 0.00010531784841075796,
      "loss": 2.1089,
      "step": 1550
    },
    {
      "epoch": 0.4889975550122249,
      "grad_norm": 0.82115238904953,
      "learning_rate": 0.00010226161369193154,
      "loss": 2.0465,
      "step": 1600
    },
    {
      "epoch": 0.5042787286063569,
      "grad_norm": 1.280161738395691,
      "learning_rate": 9.920537897310513e-05,
      "loss": 1.9169,
      "step": 1650
    },
    {
      "epoch": 0.519559902200489,
      "grad_norm": 0.873508095741272,
      "learning_rate": 9.614914425427873e-05,
      "loss": 2.0834,
      "step": 1700
    },
    {
      "epoch": 0.534841075794621,
      "grad_norm": 0.9949876070022583,
      "learning_rate": 9.309290953545232e-05,
      "loss": 2.0411,
      "step": 1750
    },
    {
      "epoch": 0.5501222493887531,
      "grad_norm": 0.965351402759552,
      "learning_rate": 9.003667481662592e-05,
      "loss": 2.0656,
      "step": 1800
    },
    {
      "epoch": 0.565403422982885,
      "grad_norm": 0.8537964224815369,
      "learning_rate": 8.698044009779952e-05,
      "loss": 1.9588,
      "step": 1850
    },
    {
      "epoch": 0.5806845965770171,
      "grad_norm": 1.0173074007034302,
      "learning_rate": 8.392420537897311e-05,
      "loss": 2.0884,
      "step": 1900
    },
    {
      "epoch": 0.5959657701711492,
      "grad_norm": 1.272697925567627,
      "learning_rate": 8.086797066014671e-05,
      "loss": 2.0225,
      "step": 1950
    },
    {
      "epoch": 0.6112469437652812,
      "grad_norm": 0.8825926780700684,
      "learning_rate": 7.78117359413203e-05,
      "loss": 1.9723,
      "step": 2000
    },
    {
      "epoch": 0.6265281173594132,
      "grad_norm": 0.9752075672149658,
      "learning_rate": 7.47555012224939e-05,
      "loss": 2.0306,
      "step": 2050
    },
    {
      "epoch": 0.6418092909535452,
      "grad_norm": 0.9927388429641724,
      "learning_rate": 7.169926650366749e-05,
      "loss": 2.0342,
      "step": 2100
    },
    {
      "epoch": 0.6570904645476773,
      "grad_norm": 1.3991519212722778,
      "learning_rate": 6.864303178484109e-05,
      "loss": 1.99,
      "step": 2150
    },
    {
      "epoch": 0.6723716381418093,
      "grad_norm": 0.7442018389701843,
      "learning_rate": 6.558679706601468e-05,
      "loss": 1.9818,
      "step": 2200
    },
    {
      "epoch": 0.6876528117359413,
      "grad_norm": 0.8460065126419067,
      "learning_rate": 6.253056234718826e-05,
      "loss": 1.9689,
      "step": 2250
    },
    {
      "epoch": 0.7029339853300733,
      "grad_norm": 1.0424977540969849,
      "learning_rate": 5.947432762836186e-05,
      "loss": 1.9596,
      "step": 2300
    },
    {
      "epoch": 0.7182151589242054,
      "grad_norm": 1.2953219413757324,
      "learning_rate": 5.641809290953546e-05,
      "loss": 1.9631,
      "step": 2350
    },
    {
      "epoch": 0.7334963325183375,
      "grad_norm": 1.3110967874526978,
      "learning_rate": 5.336185819070905e-05,
      "loss": 1.9825,
      "step": 2400
    },
    {
      "epoch": 0.7487775061124694,
      "grad_norm": 0.8726051449775696,
      "learning_rate": 5.030562347188265e-05,
      "loss": 2.0209,
      "step": 2450
    },
    {
      "epoch": 0.7640586797066015,
      "grad_norm": 0.7669264078140259,
      "learning_rate": 4.724938875305624e-05,
      "loss": 2.025,
      "step": 2500
    }
  ],
  "logging_steps": 50,
  "max_steps": 3272,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1310990008320000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
